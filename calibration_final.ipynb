{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b1f07a",
   "metadata": {},
   "source": [
    "## Calibration and rectification of the checkerboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2df9611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: Individual Camera Calibrations\n",
      "============================================================\n",
      "Processing 19 images with 13 checkerboards...\n",
      "Cycling through checkerboards deterministically\n",
      "  Image 1: Detected checkerboard 0 (size 11x7)\n",
      "  Image 2: Detected checkerboard 1 (size 11x7)\n",
      "  Image 3: Detected checkerboard 2 (size 7x5)\n",
      "  Image 4: Detected checkerboard 3 (size 7x5)\n",
      "  Image 5: Detected checkerboard 4 (size 7x5)\n",
      "  Image 6: Detected checkerboard 5 (size 5x15)\n",
      "  Image 7: Failed to detect checkerboard 6\n",
      "  Image 8: Detected checkerboard 7 (size 5x7)\n",
      "  Image 9: Detected checkerboard 8 (size 7x5)\n",
      "  Image 10: Detected checkerboard 9 (size 5x7)\n",
      "  Image 11: Detected checkerboard 10 (size 5x7)\n",
      "  Image 12: Detected checkerboard 11 (size 5x7)\n",
      "  Image 13: Detected checkerboard 12 (size 7x5)\n",
      "  Image 14: Detected checkerboard 0 (size 11x7)\n",
      "  Image 15: Detected checkerboard 1 (size 11x7)\n",
      "  Image 16: Detected checkerboard 2 (size 7x5)\n",
      "  Image 17: Detected checkerboard 3 (size 7x5)\n",
      "  Image 18: Detected checkerboard 4 (size 7x5)\n",
      "  Image 19: Detected checkerboard 5 (size 5x15)\n",
      "Total successful detections: 18/19\n",
      "\n",
      "============================================================\n",
      "Calibrating Camera 2\n",
      "============================================================\n",
      "Initial calibration with 18 views...\n",
      "\n",
      "Final Camera 2 Results:\n",
      "  RMS Error: 0.9406\n",
      "  Views Used: 18\n",
      "  Camera Matrix:\n",
      "[[1.05804110e+03 0.00000000e+00 6.91427458e+02]\n",
      " [0.00000000e+00 9.72606340e+02 2.58049593e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "  Distortion: [-0.10718377 -0.0629079  -0.00076426  0.00059902  0.08754877  0.12395294\n",
      "  0.08721847 -0.01906451  0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "Processing 19 images with 13 checkerboards...\n",
      "Cycling through checkerboards deterministically\n",
      "  Image 1: Detected checkerboard 0 (size 11x7)\n",
      "  Image 2: Detected checkerboard 1 (size 11x7)\n",
      "  Image 3: Failed to detect checkerboard 2\n",
      "  Image 4: Detected checkerboard 3 (size 7x5)\n",
      "  Image 5: Detected checkerboard 4 (size 7x5)\n",
      "  Image 6: Failed to detect checkerboard 5\n",
      "  Image 7: Failed to detect checkerboard 6\n",
      "  Image 8: Detected checkerboard 7 (size 5x7)\n",
      "  Image 9: Detected checkerboard 8 (size 7x5)\n",
      "  Image 10: Detected checkerboard 9 (size 5x7)\n",
      "  Image 11: Detected checkerboard 10 (size 5x7)\n",
      "  Image 12: Detected checkerboard 11 (size 5x7)\n",
      "  Image 13: Detected checkerboard 12 (size 7x5)\n",
      "  Image 14: Detected checkerboard 0 (size 11x7)\n",
      "  Image 15: Detected checkerboard 1 (size 11x7)\n",
      "  Image 16: Detected checkerboard 2 (size 7x5)\n",
      "  Image 17: Detected checkerboard 3 (size 7x5)\n",
      "  Image 18: Detected checkerboard 4 (size 7x5)\n",
      "  Image 19: Failed to detect checkerboard 5\n",
      "Total successful detections: 15/19\n",
      "\n",
      "============================================================\n",
      "Calibrating Camera 3\n",
      "============================================================\n",
      "Initial calibration with 15 views...\n",
      "\n",
      "Final Camera 3 Results:\n",
      "  RMS Error: 0.8666\n",
      "  Views Used: 15\n",
      "  Camera Matrix:\n",
      "[[918.00900437   0.         693.73738937]\n",
      " [  0.         901.22967472 265.42136891]\n",
      " [  0.           0.           1.        ]]\n",
      "  Distortion: [-1.39197217e-01  5.90250500e-01 -1.24789341e-03 -1.91494034e-02\n",
      "  1.73077481e+00  2.84097579e-01 -7.48050059e-02  2.98200559e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "\n",
      "============================================================\n",
      "STEP 2: Stereo Calibration\n",
      "============================================================\n",
      "\n",
      "Gathering synchronized stereo detections...\n",
      "Cycling through 13 checkerboard pairs\n",
      "  Image pair 1: Synchronized checkerboard 0\n",
      "  Image pair 2: Synchronized checkerboard 1\n",
      "  Image pair 3: Failed to detect checkerboard 2 in both cameras\n",
      "  Image pair 4: Synchronized checkerboard 3\n",
      "  Image pair 5: Synchronized checkerboard 4\n",
      "  Image pair 6: Failed to detect checkerboard 5 in both cameras\n",
      "  Image pair 7: Failed to detect checkerboard 6 in both cameras\n",
      "  Image pair 8: Synchronized checkerboard 7\n",
      "  Image pair 9: Synchronized checkerboard 8\n",
      "  Image pair 10: Synchronized checkerboard 9\n",
      "  Image pair 11: Synchronized checkerboard 10\n",
      "  Image pair 12: Synchronized checkerboard 11\n",
      "  Image pair 13: Synchronized checkerboard 12\n",
      "  Image pair 14: Synchronized checkerboard 0\n",
      "  Image pair 15: Synchronized checkerboard 1\n",
      "  Image pair 16: Synchronized checkerboard 2\n",
      "  Image pair 17: Synchronized checkerboard 3\n",
      "  Image pair 18: Synchronized checkerboard 4\n",
      "  Image pair 19: Failed to detect checkerboard 5 in both cameras\n",
      "Total synchronized detections: 15/19\n",
      "\n",
      "Performing stereo calibration...\n",
      "\n",
      "Stereo Calibration Results:\n",
      "  RMS Error: 17.5630\n",
      "  Baseline: 3.9987 units\n",
      "  Rotation (deg): 2.1357\n",
      "\n",
      "============================================================\n",
      "STEP 3: Stereo Rectification\n",
      "============================================================\n",
      "Rectifying images...\n",
      "Done! Check the 'rectified' folder for output.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "checkerboards_2 = [\n",
    "    (137, 124, 310, 332, 11, 7),  \n",
    "    (371, 171, 476, 317, 11, 7),  \n",
    "    (456, 65, 638, 149, 7, 5),    \n",
    "    (796, 134, 915, 224, 7, 5),    \n",
    "    (1032, 69, 1205, 150, 7, 5), \n",
    "    (1233, 164, 1317, 447, 5, 15),\n",
    "    (1327, 187, 1386, 358, 5, 7), \n",
    "    (1102, 259, 1189, 372, 5, 7),  \n",
    "    (998, 385, 1152, 461, 7, 5),   \n",
    "    (806, 298, 899, 420, 5, 7),    \n",
    "    (681, 298, 775, 415, 5, 7),    \n",
    "    (508, 272, 611, 392, 5, 7),   \n",
    "    (501, 388, 673, 491, 7, 5),    \n",
    "]\n",
    "\n",
    "checkerboards_3 = [\n",
    "    (74, 147, 239, 329, 11, 7),  \n",
    "    (303, 181, 403, 315, 11, 7), \n",
    "    (367, 80, 539, 162, 7, 5),  \n",
    "    (701, 134, 826, 222, 7, 5), \n",
    "    (911, 65, 1072, 142, 7, 5), \n",
    "    (1125, 149, 1197, 431, 5, 15), \n",
    "    (1206, 173, 1269, 335, 5, 7),\n",
    "    (1000, 244, 1091, 363, 5, 7),\n",
    "    (886, 369, 1039, 446, 7, 5), \n",
    "    (721, 298, 815, 408, 5, 7), \n",
    "    (609, 294, 691, 407, 5, 7), \n",
    "    (441, 271, 533, 383, 5, 7), \n",
    "    (415, 377, 575, 476, 7, 5), \n",
    "]\n",
    "\n",
    "def preprocess_image(gray_img):\n",
    "    \"\"\"Apply unsharp masking for sharper edges\"\"\"\n",
    "    blurred = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "    \n",
    "    # Unsharp mask: original + alpha * (original - blurred)\n",
    "    alpha = 4 # Sharpening strength\n",
    "    sharpened = cv2.addWeighted(gray_img, 1 + alpha, blurred, -alpha, 0)\n",
    "    \n",
    "    diff = cv2.subtract(gray_img, blurred)\n",
    "    enhanced = cv2.subtract(sharpened, diff)\n",
    "    \n",
    "    equalized = cv2.equalizeHist(enhanced)\n",
    "    return equalized\n",
    "\n",
    "def detect_single_checkerboard(gray_img, checkerboard_roi, criteria):\n",
    "    \"\"\"Detect a single checkerboard in the full image using ROI hint\"\"\"\n",
    "    x1, y1, x2, y2, nv, nh = checkerboard_roi\n",
    "    \n",
    "    # Create object points for this checkerboard\n",
    "    objp = np.zeros((nh * nv, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nv, 0:nh].T.reshape(-1, 2)\n",
    "    \n",
    "    # Extract ROI for detection hint (but don't crop the full image)\n",
    "    roi_gray = gray_img[y1:y2, x1:x2]\n",
    "    flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "    # Try to find checkerboard corners in the ROI\n",
    "    ret, corners = cv2.findChessboardCorners(roi_gray, (nv, nh), None, flags)\n",
    "\n",
    "    if ret:\n",
    "        # Adjust corners to full image coordinates\n",
    "        corners[:, 0, 0] += x1\n",
    "        corners[:, 0, 1] += y1\n",
    "        # Refine corners on the full image (not cropped)\n",
    "        corners_refined = cv2.cornerSubPix(gray_img, corners, (5, 5), (-1, -1), criteria)\n",
    "        img_display = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2BGR)\n",
    "        # cv2.drawChessboardCorners(img_display, (nv, nh), corners_refined, ret)\n",
    "        # cv2.imshow(\"Detected Checkerboard\", img_display)\n",
    "        # cv2.waitKey(1000)\n",
    "        return objp, corners_refined\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def gather_calibration_data_cycling(image_dir, checkerboards):\n",
    "    \"\"\"Gather detections cycling through one checkerboard per image\"\"\"\n",
    "    images = sorted(glob.glob(os.path.join(image_dir, '*.png')))\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    \n",
    "    all_objpoints = []\n",
    "    all_imgpoints = []\n",
    "    num_checkerboards = len(checkerboards)\n",
    "    \n",
    "    print(f\"Processing {len(images)} images with {num_checkerboards} checkerboards...\")\n",
    "    print(f\"Cycling through checkerboards deterministically\")\n",
    "    \n",
    "    for i, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Preprocess image\n",
    "        processed = preprocess_image(gray)\n",
    "        \n",
    "        # Select checkerboard for this image (cycle through them)\n",
    "        checkerboard_idx = i % num_checkerboards\n",
    "        checkerboard = checkerboards[checkerboard_idx]\n",
    "        \n",
    "        # Detect the selected checkerboard\n",
    "        objp, imgp = detect_single_checkerboard(processed, checkerboard, criteria)\n",
    "        \n",
    "        if objp is not None:\n",
    "            all_objpoints.append(objp)\n",
    "            all_imgpoints.append(imgp)\n",
    "            print(f\"  Image {i+1}: Detected checkerboard {checkerboard_idx} (size {checkerboard[4]}x{checkerboard[5]})\")\n",
    "        else:\n",
    "            print(f\"  Image {i+1}: Failed to detect checkerboard {checkerboard_idx}\")\n",
    "    \n",
    "    print(f\"Total successful detections: {len(all_objpoints)}/{len(images)}\")\n",
    "    return all_objpoints, all_imgpoints, gray.shape[::-1]\n",
    "\n",
    "def calibrate_camera_robust(objpoints, imgpoints, image_size, camera_name):\n",
    "    \"\"\"Calibrate camera with robust outlier rejection\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Calibrating {camera_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Initial calibration with all data\n",
    "    print(f\"Initial calibration with {len(objpoints)} views...\")\n",
    "    flags = cv2.CALIB_RATIONAL_MODEL  # Better distortion model\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints, image_size, None, None, flags=flags\n",
    "    )\n",
    "    print(f\"\\nFinal {camera_name} Results:\")\n",
    "    print(f\"  RMS Error: {ret:.4f}\")\n",
    "    print(f\"  Views Used: {len(objpoints)}\")\n",
    "    print(f\"  Camera Matrix:\\n{mtx}\")\n",
    "    print(f\"  Distortion: {dist.ravel()}\")\n",
    "    \n",
    "    return ret, mtx, dist, objpoints, imgpoints\n",
    "\n",
    "def gather_stereo_data_cycling(images_2, images_3, checkerboards_2, checkerboards_3):\n",
    "    \"\"\"Gather synchronized stereo detections cycling through checkerboards\"\"\"\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    \n",
    "    objpoints = []\n",
    "    imgpoints_2 = []\n",
    "    imgpoints_3 = []\n",
    "    num_checkerboards = len(checkerboards_2)\n",
    "    \n",
    "    print(\"\\nGathering synchronized stereo detections...\")\n",
    "    print(f\"Cycling through {num_checkerboards} checkerboard pairs\")\n",
    "    \n",
    "    for i, (fname_2, fname_3) in enumerate(zip(images_2, images_3)):\n",
    "        img_2 = cv2.imread(fname_2)\n",
    "        img_3 = cv2.imread(fname_3)\n",
    "        gray_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2GRAY)\n",
    "        gray_3 = cv2.cvtColor(img_3, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Preprocess both images\n",
    "        processed_2 = preprocess_image(gray_2)\n",
    "        processed_3 = preprocess_image(gray_3)\n",
    "        \n",
    "        # Select checkerboard for this image pair (cycle through them)\n",
    "        checkerboard_idx = i % num_checkerboards\n",
    "        \n",
    "        # Detect in both cameras\n",
    "        objp_2, imgp_2 = detect_single_checkerboard(processed_2, checkerboards_2[checkerboard_idx], criteria)\n",
    "        objp_3, imgp_3 = detect_single_checkerboard(processed_3, checkerboards_3[checkerboard_idx], criteria)\n",
    "        \n",
    "        # Only keep if detected in BOTH cameras\n",
    "        if objp_2 is not None and objp_3 is not None:\n",
    "            if objp_2.shape == objp_3.shape:  # Verify same board size\n",
    "                objpoints.append(objp_2)\n",
    "                imgpoints_2.append(imgp_2)\n",
    "                imgpoints_3.append(imgp_3)\n",
    "                print(f\"  Image pair {i+1}: Synchronized checkerboard {checkerboard_idx}\")\n",
    "            else:\n",
    "                print(f\"  Image pair {i+1}: Size mismatch for checkerboard {checkerboard_idx}\")\n",
    "        else:\n",
    "            print(f\"  Image pair {i+1}: Failed to detect checkerboard {checkerboard_idx} in both cameras\")\n",
    "    \n",
    "    print(f\"Total synchronized detections: {len(objpoints)}/{len(images_2)}\")\n",
    "    return objpoints, imgpoints_2, imgpoints_3\n",
    "\n",
    "# Main calibration pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Individual camera calibrations\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 1: Individual Camera Calibrations\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Camera 2\n",
    "    obj_2, img_2, size_2 = gather_calibration_data_cycling(\n",
    "        '34759_final_project_raw/calib/image_02/data', checkerboards_2\n",
    "    )\n",
    "    rms_2, mtx_2, dist_2, obj_2_filtered, img_2_filtered = calibrate_camera_robust(\n",
    "        obj_2, img_2, size_2, \"Camera 2\"\n",
    "    )\n",
    "    \n",
    "    # Camera 3\n",
    "    obj_3, img_3, size_3 = gather_calibration_data_cycling(\n",
    "        '34759_final_project_raw/calib/image_03/data', checkerboards_3\n",
    "    )\n",
    "    rms_3, mtx_3, dist_3, obj_3_filtered, img_3_filtered = calibrate_camera_robust(\n",
    "        obj_3, img_3, size_3, \"Camera 3\"\n",
    "    )\n",
    "    \n",
    "    # Step 2: Stereo calibration\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 2: Stereo Calibration\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    images_2 = sorted(glob.glob('34759_final_project_raw/calib/image_02/data/*.png'))\n",
    "    images_3 = sorted(glob.glob('34759_final_project_raw/calib/image_03/data/*.png'))\n",
    "    \n",
    "    obj_stereo, img_2_stereo, img_3_stereo = gather_stereo_data_cycling(\n",
    "        images_2, images_3, checkerboards_2, checkerboards_3\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPerforming stereo calibration...\")\n",
    "    flags = cv2.CALIB_FIX_INTRINSIC  # Use individual calibrations\n",
    "    ret_stereo, mtx_2_s, dist_2_s, mtx_3_s, dist_3_s, R, T, E, F = cv2.stereoCalibrate(\n",
    "        obj_stereo, img_2_stereo, img_3_stereo,\n",
    "        mtx_2, dist_2, mtx_3, dist_3, size_2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-6),\n",
    "        flags=flags\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nStereo Calibration Results:\")\n",
    "    print(f\"  RMS Error: {ret_stereo:.4f}\")\n",
    "    print(f\"  Baseline: {np.linalg.norm(T):.4f} units\")\n",
    "    print(f\"  Rotation (deg): {np.linalg.norm(cv2.Rodrigues(R)[0]) * 180 / np.pi:.4f}\")\n",
    "    \n",
    "    # Step 3: Stereo rectification\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 3: Stereo Rectification\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    H, W = size_2[1], size_2[0]\n",
    "    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(\n",
    "        mtx_2, dist_2, mtx_3, dist_3, (W, H), R, T, alpha=0.25\n",
    "    )\n",
    "    \n",
    "    map1_2, map2_2 = cv2.initUndistortRectifyMap(mtx_2, dist_2, R1, P1, (W, H), cv2.CV_16SC2)\n",
    "    map1_3, map2_3 = cv2.initUndistortRectifyMap(mtx_3, dist_3, R2, P2, (W, H), cv2.CV_16SC2)\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs('rectified/image_02', exist_ok=True)\n",
    "    os.makedirs('rectified/image_03', exist_ok=True)\n",
    "    \n",
    "    print(\"Rectifying images...\")\n",
    "    for i, (fname_2, fname_3) in enumerate(zip(images_2, images_3)):\n",
    "        img_2 = cv2.imread(fname_2)\n",
    "        img_3 = cv2.imread(fname_3)\n",
    "        \n",
    "        rectified_2 = cv2.remap(img_2, map1_2, map2_2, cv2.INTER_LINEAR)\n",
    "        rectified_3 = cv2.remap(img_3, map1_3, map2_3, cv2.INTER_LINEAR)\n",
    "        \n",
    "        cv2.imwrite(f'rectified/image_02/rectified_2_{i:04d}.png', rectified_2)\n",
    "        cv2.imwrite(f'rectified/image_03/rectified_3_{i:04d}.png', rectified_3)\n",
    "    \n",
    "    print(\"Done! Check the 'rectified' folder for output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbf962",
   "metadata": {},
   "source": [
    "## Rectification of the sequence images using the provided camera calibration paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a207df9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rectification maps for Camera 02 and 03...\n",
      "Maps successfully generated.\n",
      "\n",
      "Processing 376 synchronized image pairs...\n",
      "Rectified images saved to 'rectified/seq03_image_02' and 'rectified/seq03_image_03'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- 1. Define Camera Calibration Parameters (from provided file input) ---\n",
    "\n",
    "def parse_calibration_file(filepath):\n",
    "    \"\"\"Parse KITTI calibration file and extract camera parameters.\"\"\"\n",
    "    calib_data = {}\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if ':' not in line:\n",
    "                continue\n",
    "            \n",
    "            key, value = line.split(':', 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            \n",
    "            # Convert numeric values to numpy arrays\n",
    "            if key.startswith(('K_', 'D_', 'R_', 'T_', 'S_', 'R_rect_', 'P_rect_')):\n",
    "                values = np.array([float(x) for x in value.split()])\n",
    "                \n",
    "                # Reshape matrices appropriately\n",
    "                if key.startswith('K_') or key.startswith('R_rect_'):\n",
    "                    values = values.reshape(3, 3)\n",
    "                elif key.startswith('P_rect_'):\n",
    "                    values = values.reshape(3, 4)\n",
    "                elif key.startswith('R_'):\n",
    "                    values = values.reshape(3, 3)\n",
    "                elif key.startswith('S_'):\n",
    "                    values = values.astype(int)  # Size should be integers\n",
    "                \n",
    "                calib_data[key] = values\n",
    "            else:\n",
    "                calib_data[key] = value\n",
    "    \n",
    "    return calib_data\n",
    "\n",
    "def load_camera_params(calib_file, cam_id):\n",
    "    \"\"\"Load parameters for a specific camera from calibration file.\"\"\"\n",
    "    calib = parse_calibration_file(calib_file)\n",
    "    \n",
    "    cam_str = f'{cam_id:02d}'\n",
    "    \n",
    "    K = calib[f'K_{cam_str}']\n",
    "    D = calib[f'D_{cam_str}']\n",
    "    R_rect = calib[f'R_rect_{cam_str}']\n",
    "    P_rect = calib[f'P_rect_{cam_str}']\n",
    "    S_rect = calib[f'S_rect_{cam_str}']\n",
    "    \n",
    "    # S_rect is [width, height]\n",
    "    size = tuple(S_rect)\n",
    "    \n",
    "    return K, D, R_rect, P_rect, size\n",
    "\n",
    "# Load calibration parameters for Camera 02 and Camera 03\n",
    "calib_file = '34759_final_project_rect/calib_cam_to_cam.txt'\n",
    "K_02, D_02, R_rect_02, P_rect_02, ORIGINAL_SIZE = load_camera_params(calib_file, 2)\n",
    "K_03, D_03, R_rect_03, P_rect_03, ORIGINAL_SIZE = load_camera_params(calib_file, 3)\n",
    "\n",
    "# --- 2. Rectification Map Generation ---\n",
    "\n",
    "def generate_rectification_maps(K, D, R_rect, P_rect, size):\n",
    "    \"\"\"Generates the Undistortion and Rectification Maps using the provided matrices.\"\"\"\n",
    "    #Use the 3x3 rotation part of P_rect as the new camera matrix for initUndistortRectifyMap\n",
    "    # CV_16SC2 is used for optimal memory and remap speed.\n",
    "    map1, map2 = cv2.initUndistortRectifyMap(\n",
    "        K, D, R_rect, P_rect[:3, :3], size, cv2.CV_16SC2\n",
    "    )\n",
    "    return map1, map2\n",
    "\n",
    "# Generate maps for both cameras\n",
    "print(\"Generating rectification maps for Camera 02 and 03...\")\n",
    "map1_02, map2_02 = generate_rectification_maps(K_02, D_02, R_rect_02, P_rect_02, ORIGINAL_SIZE)\n",
    "map1_03, map2_03 = generate_rectification_maps(K_03, D_03, R_rect_03, P_rect_03, ORIGINAL_SIZE)\n",
    "print(\"Maps successfully generated.\")\n",
    "\n",
    "# --- 3. Image Loading and Rectification ---\n",
    "\n",
    "def rectify_all_images():\n",
    "    \"\"\"Loads all raw images, rectifies them, and saves the result.\"\"\"\n",
    "    \n",
    "    # Input directories \n",
    "    image_dir_02 = '34759_final_project_raw/seq_03/image_02/data'\n",
    "    image_dir_03 = '34759_final_project_raw/seq_03/image_03/data'\n",
    "    \n",
    "    # Output directories \n",
    "    output_dir_02 = 'rectified/seq03_image_02'\n",
    "    output_dir_03 = 'rectified/seq03_image_03'\n",
    "    \n",
    "    # Get sorted list of images\n",
    "    images_02 = sorted(glob.glob(os.path.join(image_dir_02, '*.png')))\n",
    "    images_03 = sorted(glob.glob(os.path.join(image_dir_03, '*.png')))\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(output_dir_02, exist_ok=True)\n",
    "    os.makedirs(output_dir_03, exist_ok=True)\n",
    "    \n",
    "    # Ensure synchronization\n",
    "    min_len = min(len(images_02), len(images_03))\n",
    "    print(f\"\\nProcessing {min_len} synchronized image pairs...\")\n",
    "\n",
    "    for i in range(min_len):\n",
    "        fname_2 = images_02[i]\n",
    "        fname_3 = images_03[i]\n",
    "        \n",
    "        # Load images\n",
    "        img_02 = cv2.imread(fname_2)\n",
    "        img_03 = cv2.imread(fname_3)\n",
    "        \n",
    "        if img_02 is None or img_03 is None:\n",
    "            print(f\"Skipping pair {i:04d}: Could not load one or both images.\")\n",
    "            continue\n",
    "            \n",
    "        # Rectify Camera 02 image\n",
    "        rectified_02 = cv2.remap(img_02, map1_02, map2_02, cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Rectify Camera 03 image\n",
    "        rectified_03 = cv2.remap(img_03, map1_03, map2_03, cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Define output filenames\n",
    "        # Use the original filename suffix or a sequential number\n",
    "        base_name = os.path.basename(fname_2)\n",
    "        \n",
    "        # Save rectified images\n",
    "        cv2.imwrite(os.path.join(output_dir_02, f'rectified_02_{base_name}'), rectified_02)\n",
    "        cv2.imwrite(os.path.join(output_dir_03, f'rectified_03_{base_name}'), rectified_03)\n",
    "        \n",
    "    print(f\"Rectified images saved to '{output_dir_02}' and '{output_dir_03}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rectify_all_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f255885a",
   "metadata": {},
   "source": [
    "## Printing of our calibration parameters for documentation and comparison to the provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd91391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CALIBRATION PARAMETERS (KITTI FORMAT)\n",
      "============================================================\n",
      "\n",
      "calib_time: 24-Nov-2025 23:16:55\n",
      "corner_dist: 9.950000e-02\n",
      "S_02: 1.392000e+03 5.120000e+02\n",
      "K_02: 1.058041e+03 0.000000e+00 6.914275e+02 0.000000e+00 9.726063e+02 2.580496e+02 0.000000e+00 0.000000e+00 1.000000e+00\n",
      "D_02: -1.071838e-01 -6.290790e-02 -7.642557e-04 5.990191e-04 8.754877e-02 1.239529e-01 8.721847e-02 -1.906451e-02 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      "R_02: 9.993501e-01 2.259417e-02 -2.808610e-02 -2.285893e-02 9.996969e-01 -9.141647e-03 2.787104e-02 9.777724e-03 9.995637e-01\n",
      "T_02: -3.958239e+00 1.354667e-01 5.508133e-01\n",
      "S_rect_02: 1.392000e+03 5.120000e+02\n",
      "R_rect_02: 9.861795e-01 -1.284881e-02 -1.651812e-01 1.189654e-02 9.999064e-01 -6.753063e-03 1.652526e-01 4.694648e-03 9.862401e-01\n",
      "P_rect_02: 8.694485e+02 0.000000e+00 8.949293e+02 0.000000e+00 0.000000e+00 8.694485e+02 2.649775e+02 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00\n",
      "\n",
      "calib_time: 24-Nov-2025 23:16:55\n",
      "corner_dist: 9.950000e-02\n",
      "S_03: 1.392000e+03 5.120000e+02\n",
      "K_03: 9.180090e+02 0.000000e+00 6.937374e+02 0.000000e+00 9.012297e+02 2.654214e+02 0.000000e+00 0.000000e+00 1.000000e+00\n",
      "D_03: -1.391972e-01 5.902505e-01 -1.247893e-03 -1.914940e-02 1.730775e+00 2.840976e-01 -7.480501e-02 2.982006e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      "R_03: 9.993501e-01 2.259417e-02 -2.808610e-02 -2.285893e-02 9.996969e-01 -9.141647e-03 2.787104e-02 9.777724e-03 9.995637e-01\n",
      "T_03: -3.958239e+00 1.354667e-01 5.508133e-01\n",
      "S_rect_03: 1.392000e+03 5.120000e+02\n",
      "R_rect_03: 9.898876e-01 -3.387789e-02 -1.377490e-01 3.467053e-02 9.993932e-01 3.358261e-03 1.375516e-01 -8.100131e-03 9.904615e-01\n",
      "P_rect_03: 8.694485e+02 0.000000e+00 8.949293e+02 -3.476642e+03 0.000000e+00 8.694485e+02 2.649775e+02 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00\n",
      "\n",
      "Calibration parameters saved to 'our_calib_cam_to_cam.txt'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def print_calibration_results(camera_idx, mtx, dist, R, T, R_rect, P_rect, image_size, corner_dist=0.0995):\n",
    "    \"\"\"\n",
    "    Print calibration parameters in KITTI format\n",
    "    \n",
    "    Args:\n",
    "        camera_idx: Camera index (0, 1, 2, 3, etc.)\n",
    "        mtx: Camera intrinsic matrix (3x3)\n",
    "        dist: Distortion coefficients\n",
    "        R: Rotation matrix (3x3) - from stereo calibration\n",
    "        T: Translation vector (3,) - from stereo calibration\n",
    "        R_rect: Rectification rotation matrix (3x3)\n",
    "        P_rect: Rectified projection matrix (3x4)\n",
    "        image_size: (width, height) tuple\n",
    "        corner_dist: Corner distance in meters (default 0.0995 for KITTI)\n",
    "    \"\"\"\n",
    "    # Get current timestamp\n",
    "    calib_time = datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "    \n",
    "    print(f\"calib_time: {calib_time}\")\n",
    "    print(f\"corner_dist: {corner_dist:.6e}\")\n",
    "    \n",
    "    # Original image size\n",
    "    width, height = image_size\n",
    "    print(f\"S_{camera_idx:02d}: {width:.6e} {height:.6e}\")\n",
    "    \n",
    "    # Camera intrinsic matrix K (flattened row-major)\n",
    "    K_flat = mtx.flatten()\n",
    "    print(f\"K_{camera_idx:02d}: {' '.join([f'{x:.6e}' for x in K_flat])}\")\n",
    "    \n",
    "    # Distortion coefficients (k1, k2, p1, p2, k3)\n",
    "    D_flat = dist.flatten()\n",
    "    print(f\"D_{camera_idx:02d}: {' '.join([f'{x:.6e}' for x in D_flat])}\")\n",
    "    \n",
    "    # Rotation matrix (flattened row-major)\n",
    "    R_flat = R.flatten()\n",
    "    print(f\"R_{camera_idx:02d}: {' '.join([f'{x:.6e}' for x in R_flat])}\")\n",
    "    \n",
    "    # Translation vector\n",
    "    T_flat = T.flatten()\n",
    "    print(f\"T_{camera_idx:02d}: {' '.join([f'{x:.6e}' for x in T_flat])}\")\n",
    "    \n",
    "    # Rectified image size\n",
    "    rect_width, rect_height = image_size  # Usually same as original\n",
    "    print(f\"S_rect_{camera_idx:02d}: {rect_width:.6e} {rect_height:.6e}\")\n",
    "    \n",
    "    # Rectification rotation matrix (flattened row-major)\n",
    "    R_rect_flat = R_rect.flatten()\n",
    "    print(f\"R_rect_{camera_idx:02d}: {' '.join([f'{x:.6e}' for x in R_rect_flat])}\")\n",
    "    \n",
    "    # Rectified projection matrix (flattened row-major, 3x4 = 12 elements)\n",
    "    P_rect_flat = P_rect.flatten()\n",
    "    print(f\"P_rect_{camera_idx:02d}: {' '.join([f'{x:.6e}' for x in P_rect_flat])}\")\n",
    "    \n",
    "    print()  # Empty line between cameras\n",
    "\n",
    "# Have to run after calibration and rectification block above as uses those variables:\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Print results:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CALIBRATION PARAMETERS (KITTI FORMAT)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Camera 2 \n",
    "    print_calibration_results(\n",
    "        camera_idx=2,\n",
    "        mtx=mtx_2,\n",
    "        dist=dist_2,\n",
    "        R=R,  # Rotation from stereo calibration\n",
    "        T=T,  # Translation from stereo calibration\n",
    "        R_rect=R1,  # Rectification rotation from stereoRectify\n",
    "        P_rect=P1,  # Projection matrix from stereoRectify\n",
    "        image_size=(W, H)\n",
    "    )\n",
    "    \n",
    "    # Camera 3 \n",
    "    print_calibration_results(\n",
    "        camera_idx=3,\n",
    "        mtx=mtx_3,\n",
    "        dist=dist_3,\n",
    "        R=R,  # Same rotation (or R.T depending on convention)\n",
    "        T=T,  # Translation from stereo calibration\n",
    "        R_rect=R2,  # Rectification rotation from stereoRectify\n",
    "        P_rect=P2,  # Projection matrix from stereoRectify\n",
    "        image_size=(W, H)\n",
    "    )\n",
    "    \n",
    "    # Optional: Save to file in KITTI format\n",
    "    with open('our_calib_cam_to_cam.txt', 'w') as f:\n",
    "        f.write(f\"calib_time: {datetime.now().strftime('%d-%b-%Y %H:%M:%S')}\\n\")\n",
    "        f.write(f\"corner_dist: 9.950000e-02\\n\")\n",
    "        \n",
    "        # Write camera 2\n",
    "        f.write(f\"S_02: {W:.6e} {H:.6e}\\n\")\n",
    "        f.write(f\"K_02: {' '.join([f'{x:.6e}' for x in mtx_2.flatten()])}\\n\")\n",
    "        f.write(f\"D_02: {' '.join([f'{x:.6e}' for x in dist_2.flatten()])}\\n\")\n",
    "        f.write(f\"R_02: {' '.join([f'{x:.6e}' for x in R.flatten()])}\\n\")\n",
    "        f.write(f\"T_02: {' '.join([f'{x:.6e}' for x in T.flatten()])}\\n\")\n",
    "        f.write(f\"S_rect_02: {W:.6e} {H:.6e}\\n\")\n",
    "        f.write(f\"R_rect_02: {' '.join([f'{x:.6e}' for x in R1.flatten()])}\\n\")\n",
    "        f.write(f\"P_rect_02: {' '.join([f'{x:.6e}' for x in P1.flatten()])}\\n\")\n",
    "        \n",
    "        # Write camera 3\n",
    "        f.write(f\"S_03: {W:.6e} {H:.6e}\\n\")\n",
    "        f.write(f\"K_03: {' '.join([f'{x:.6e}' for x in mtx_3.flatten()])}\\n\")\n",
    "        f.write(f\"D_03: {' '.join([f'{x:.6e}' for x in dist_3.flatten()])}\\n\")\n",
    "        f.write(f\"R_03: {' '.join([f'{x:.6e}' for x in R.flatten()])}\\n\")\n",
    "        f.write(f\"T_03: {' '.join([f'{x:.6e}' for x in T.flatten()])}\\n\")\n",
    "        f.write(f\"S_rect_03: {W:.6e} {H:.6e}\\n\")\n",
    "        f.write(f\"R_rect_03: {' '.join([f'{x:.6e}' for x in R2.flatten()])}\\n\")\n",
    "        f.write(f\"P_rect_03: {' '.join([f'{x:.6e}' for x in P2.flatten()])}\\n\")\n",
    "    \n",
    "    print(\"Calibration parameters saved to 'our_calib_cam_to_cam.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c908792",
   "metadata": {},
   "source": [
    "## Generating videos of our camera calibration & rectification results on the checkerboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ddc79df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved comparison_frames/frame_0000.png\n",
      "Saved comparison_frames/frame_0001.png\n",
      "Saved comparison_frames/frame_0002.png\n",
      "Saved comparison_frames/frame_0003.png\n",
      "Saved comparison_frames/frame_0004.png\n",
      "Saved comparison_frames/frame_0005.png\n",
      "Saved comparison_frames/frame_0006.png\n",
      "Saved comparison_frames/frame_0007.png\n",
      "Saved comparison_frames/frame_0008.png\n",
      "Saved comparison_frames/frame_0009.png\n",
      "Saved comparison_frames/frame_0010.png\n",
      "Saved comparison_frames/frame_0011.png\n",
      "Saved comparison_frames/frame_0012.png\n",
      "Saved comparison_frames/frame_0013.png\n",
      "Saved comparison_frames/frame_0014.png\n",
      "Saved comparison_frames/frame_0015.png\n",
      "Saved comparison_frames/frame_0016.png\n",
      "Saved comparison_frames/frame_0017.png\n",
      "Saved comparison_frames/frame_0018.png\n",
      "\n",
      "Frames saved to comparison_frames/\n",
      "To create video with ffmpeg, run:\n",
      "ffmpeg -framerate 2 -i comparison_frames/frame_%04d.png -c:v libx264 -pix_fmt yuv420p output.mp4\n",
      "Using H.264 codec...\n",
      "Writing frame_0000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x34363248/'H264' is not supported with codec id 27 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x31637661/'avc1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing frame_0001.png\n",
      "Writing frame_0002.png\n",
      "Writing frame_0003.png\n",
      "Writing frame_0004.png\n",
      "Writing frame_0005.png\n",
      "Writing frame_0006.png\n",
      "Writing frame_0007.png\n",
      "Writing frame_0008.png\n",
      "Writing frame_0009.png\n",
      "Writing frame_0010.png\n",
      "Writing frame_0011.png\n",
      "Writing frame_0012.png\n",
      "Writing frame_0013.png\n",
      "Writing frame_0014.png\n",
      "Writing frame_0015.png\n",
      "Writing frame_0016.png\n",
      "Writing frame_0017.png\n",
      "Writing frame_0018.png\n",
      "\n",
      "✓ Video created: rectification_comparison.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_comparison_frames(num_images=19, output_dir=\"comparison_frames\"):\n",
    "    \"\"\"Save individual frames, then combine with ffmpeg\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    raw_left_template = \"34759_final_project_raw/calib/image_02/data/{:010d}.png\"\n",
    "    raw_right_template = \"34759_final_project_raw/calib/image_03/data/{:010d}.png\"\n",
    "    rect_left_template = \"rectified/image_02/rectified_2_{:04d}.png\"\n",
    "    rect_right_template = \"rectified/image_03/rectified_3_{:04d}.png\"\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        raw_left = cv2.imread(raw_left_template.format(i))\n",
    "        raw_right = cv2.imread(raw_right_template.format(i))\n",
    "        rect_left = cv2.imread(rect_left_template.format(i))\n",
    "        rect_right = cv2.imread(rect_right_template.format(i))\n",
    "        \n",
    "        if any(img is None for img in [raw_left, raw_right, rect_left, rect_right]):\n",
    "            print(f\"Warning: Could not load all images for frame {i}\")\n",
    "            continue\n",
    "        \n",
    "        cv2.putText(raw_left, f\"Left Raw - {i}\", (10, 40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(rect_left, f\"Left Rectified - {i}\", (10, 40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(raw_right, f\"Right Raw - {i}\", (10, 40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(rect_right, f\"Right Rectified - {i}\", (10, 40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        top_row = np.hstack([raw_left, rect_left])\n",
    "        bottom_row = np.hstack([raw_right, rect_right])\n",
    "        combined = np.vstack([top_row, bottom_row])\n",
    "        \n",
    "        output_path = os.path.join(output_dir, f\"frame_{i:04d}.png\")\n",
    "        cv2.imwrite(output_path, combined)\n",
    "        print(f\"Saved {output_path}\")\n",
    "    \n",
    "    print(f\"\\nFrames saved to {output_dir}/\")\n",
    "    print(\"To create video with ffmpeg, run:\")\n",
    "    print(f\"ffmpeg -framerate 2 -i {output_dir}/frame_%04d.png -c:v libx264 -pix_fmt yuv420p output.mp4\")\n",
    "\n",
    "create_comparison_frames()\n",
    "\n",
    "def frames_to_video(frames_dir=\"comparison_frames\", output_name=\"rectification_comparison.mp4\", fps=2):\n",
    "    \"\"\"Convert saved frames to video using OpenCV\"\"\"\n",
    "    \n",
    "    # Get list of frame files\n",
    "    frame_files = sorted([f for f in os.listdir(frames_dir) if f.endswith('.png')])\n",
    "    \n",
    "    if not frame_files:\n",
    "        print(f\"No frames found in {frames_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Read first frame to get dimensions\n",
    "    first_frame = cv2.imread(os.path.join(frames_dir, frame_files[0]))\n",
    "    h, w = first_frame.shape[:2]\n",
    "    \n",
    "    # Try different codecs\n",
    "    for codec_name, codec_code, extension in [\n",
    "        ('H.264', 'H264', '.mp4'),\n",
    "        ('X264', 'X264', '.mp4'),\n",
    "        ('MJPEG', 'MJPG', '.avi'),\n",
    "        ('XVID', 'XVID', '.avi')\n",
    "    ]:\n",
    "        try:\n",
    "            output_file = output_name.replace('.mp4', extension)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*codec_code)\n",
    "            out = cv2.VideoWriter(output_file, fourcc, fps, (w, h))\n",
    "            \n",
    "            if out.isOpened():\n",
    "                print(f\"Using {codec_name} codec...\")\n",
    "                \n",
    "                for frame_file in frame_files:\n",
    "                    frame = cv2.imread(os.path.join(frames_dir, frame_file))\n",
    "                    out.write(frame)\n",
    "                    print(f\"Writing {frame_file}\")\n",
    "                \n",
    "                out.release()\n",
    "                print(f\"\\n✓ Video created: {output_file}\")\n",
    "                return\n",
    "            else:\n",
    "                out.release()\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(\"All codecs failed. Please install ffmpeg.\")\n",
    "\n",
    "# Run this after creating the frames\n",
    "frames_to_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d44ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evolution video for image pair 0...\n",
      "\n",
      "Processing image pair 0\n",
      "  Added 105 frames\n",
      "\n",
      "✓ Video saved as rectification_evolution.mp4\n",
      "  Total frames: 105\n",
      "  FPS: 30\n",
      "  Duration: 3.5 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def create_transition_video(image_index=0, output_name=\"rectification_evolution.mp4\", fps=30):\n",
    "    \"\"\"\n",
    "    Create a video showing smooth transition from raw to rectified for one image pair.\n",
    "    Shows: Raw -> Blend transition -> Rectified -> Difference map\n",
    "    \n",
    "    Args:\n",
    "        image_index: which image pair to use (0 to 18)\n",
    "        output_name: output video filename\n",
    "        fps: frames per second\n",
    "    \"\"\"\n",
    "    \n",
    "    # Path templates\n",
    "    raw_left_template = \"34759_final_project_raw/calib/image_02/data/{:010d}.png\"\n",
    "    raw_right_template = \"34759_final_project_raw/calib/image_03/data/{:010d}.png\"\n",
    "    rect_left_template = \"rectified/image_02/rectified_2_{:04d}.png\"\n",
    "    rect_right_template = \"rectified/image_03/rectified_3_{:04d}.png\"\n",
    "    \n",
    "    # Load first image to get dimensions\n",
    "    first_img = cv2.imread(raw_left_template.format(0))\n",
    "    if first_img is None:\n",
    "        print(f\"Error: Could not load {raw_left_template.format(0)}\")\n",
    "        return\n",
    "    \n",
    "    h, w = first_img.shape[:2]\n",
    "    \n",
    "    # Video writer - side by side (left and right cameras)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, fps, (w * 2, h))\n",
    "    \n",
    "    if not out.isOpened():\n",
    "        print(\"mp4v codec failed, trying avc1...\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "        out = cv2.VideoWriter(output_name, fourcc, fps, (w * 2, h))\n",
    "    \n",
    "    print(f\"Creating evolution video for image pair {image_index}...\")\n",
    "    \n",
    "    # Number of transition frames between stages\n",
    "    transition_frames = 30  # 1 second at 30fps\n",
    "    hold_frames = 15  # 0.5 seconds hold on each stage\n",
    "    \n",
    "    i = image_index\n",
    "    print(f\"\\nProcessing image pair {i}\")\n",
    "    \n",
    "    # Load all 4 images\n",
    "    raw_left = cv2.imread(raw_left_template.format(i))\n",
    "    raw_right = cv2.imread(raw_right_template.format(i))\n",
    "    rect_left = cv2.imread(rect_left_template.format(i))\n",
    "    rect_right = cv2.imread(rect_right_template.format(i))\n",
    "    \n",
    "    if any(img is None for img in [raw_left, raw_right, rect_left, rect_right]):\n",
    "        print(f\"Error: Could not load all images for frame {i}\")\n",
    "        return\n",
    "    \n",
    "    # Convert to float for blending\n",
    "    raw_left_f = raw_left.astype(float)\n",
    "    raw_right_f = raw_right.astype(float)\n",
    "    rect_left_f = rect_left.astype(float)\n",
    "    rect_right_f = rect_right.astype(float)\n",
    "    \n",
    "    # Create difference images (enhanced for visibility)\n",
    "    diff_left = cv2.absdiff(raw_left, rect_left)\n",
    "    diff_right = cv2.absdiff(raw_right, rect_right)\n",
    "    # Enhance difference visibility\n",
    "    diff_left = cv2.convertScaleAbs(diff_left, alpha=3)\n",
    "    diff_right = cv2.convertScaleAbs(diff_right, alpha=3)\n",
    "    \n",
    "    # Stage 1: Hold on raw images\n",
    "    for _ in range(hold_frames):\n",
    "        frame_left = raw_left.copy()\n",
    "        frame_right = raw_right.copy()\n",
    "        cv2.putText(frame_left, f\"Left Raw - Frame {i}\", (10, 40), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame_right, f\"Right Raw - Frame {i}\", (10, 40), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        combined = np.hstack([frame_left, frame_right])\n",
    "        out.write(combined)\n",
    "    \n",
    "    # Stage 2: Transition from raw to rectified\n",
    "    for t in range(transition_frames):\n",
    "        alpha = t / transition_frames\n",
    "        \n",
    "        # Blend images\n",
    "        blend_left = cv2.addWeighted(raw_left, 1-alpha, rect_left, alpha, 0)\n",
    "        blend_right = cv2.addWeighted(raw_right, 1-alpha, rect_right, alpha, 0)\n",
    "        \n",
    "        cv2.putText(blend_left, f\"Left Transitioning... {int(alpha*100)}%\", (10, 40), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        cv2.putText(blend_right, f\"Right Transitioning... {int(alpha*100)}%\", (10, 40), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        \n",
    "        combined = np.hstack([blend_left, blend_right])\n",
    "        out.write(combined)\n",
    "    \n",
    "    # Stage 3: Hold on rectified images\n",
    "    for _ in range(hold_frames):\n",
    "        frame_left = rect_left.copy()\n",
    "        frame_right = rect_right.copy()\n",
    "        cv2.putText(frame_left, f\"Left Rectified - Frame {i}\", (10, 40), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame_right, f\"Right Rectified - Frame {i}\", (10, 40), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        combined = np.hstack([frame_left, frame_right])\n",
    "        out.write(combined)\n",
    "    \n",
    "    print(f\"  Added {hold_frames*3 + transition_frames*2} frames\")\n",
    "    \n",
    "    out.release()\n",
    "    \n",
    "    total_frames = hold_frames * 3 + transition_frames * 2\n",
    "    print(f\"\\n✓ Video saved as {output_name}\")\n",
    "    print(f\"  Total frames: {total_frames}\")\n",
    "    print(f\"  FPS: {fps}\")\n",
    "    print(f\"  Duration: {total_frames/fps:.1f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create the evolution video for image 0 (change this to use a different image)\n",
    "    create_transition_video(image_index=0, output_name=\"rectification_evolution.mp4\", fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
